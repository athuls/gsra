################################################################################
# metarun configuration
# Note: variables starting with "meta_" are reserved for meta configuration

meta_command = mtdetect # command to run
# optional meta variables ######################################################
meta_name = ${name}_${machine} # name of this meta job
meta_max_cpus = 10 # maximum number of cpus to use at the same time
meta_output_dir = ${root}/../out/ # directory where to write outputs
meta_gnuplot_params="set grid ytics;set ytics;set mytics;set grid mytics;set logscale y; set mxtics; set grid xtics; " # extra gnuplot parameters
# analyze processes output or not. if 0, the meta_trainer will have no notion
# of iteration and will only send 1 report at the very end.
# if 1, meta_trainer will try to find iteration and other variable values
# in each process' output.
meta_analyze = 1
meta_send_email = 1 # emailing results or not
meta_email=${myemail} # email to use (use environment variable "myemail")
# iterations at which to send an email
#meta_email_iters = 0,1,2,3,4,5,7,10,15,20,30,50,75,100,200
#meta_email_period = 1 # send email with this freq (if email_iters not defined)
meta_watch_interval = 5 # interval sec to analyze outputs and check who's alive
# variables to minimize, process and iteration with lowest value will
# be used to report best weights, or start consequent training
meta_minimize = 1FPPI #test_errors,errors,test_energy,energy
meta_ignore_iter0 = 1 # do not take results for i = 0 into account
meta_sticky_vars = job,config,classes # vars to keep around at each iterations
meta_send_best = 25 # send n best answers that minimize meta_minimize's value

################################################################################
# local program configuration

name=inria
machine = ${HOSTNAME}a
ebl= ${HOME}/eblpierre/ # eblearn root
root = ${HOME}/${machine}data/ped/${name}/ds/ # datasets root
#root2 = ${ebl}/demos/pedestrians/trained/ # trained weights root

# network high level switches ##################################################

net = cscsc # net archictecture
color = 0 # use color or not
manual_load = 0 # manually load weights for individual modules

# architecture #################################################################

arch = ${arch_${net}} # global architecture
mirror = 0 # mirror instead of zero-padding (default)
nonlin = tanh # stdsig # non-linearity module

# layers
c0 = conv0,addc0,${nonlin}0,diag0,abs0,wstd0
s1 = subs1,addc1,${nonlin}1
c2 = conv2,addc2,${nonlin}2,diag2,abs2,wstd2
s3 = subs3,addc3,${nonlin}3
c4 = conv4,addc4,${nonlin}4
f5 = linear5,addc5,${nonlin}5

# machines
arch_cscsc = ${c0},${s1},${c2},${s3},${c4}
arch_cscscf = ${c0},${s1},${c2},${s3},${c4},${f5}

# modules parameters
inputh = 78 # input's height
inputw = 38 # input's width
conv0_kerh = 7 # convolution kernel's height
conv0_kerw = 7 # convolution kernel's width
conv0_strideh = 1 # convolution stride in height
conv0_stridew = 1 # convolution stride in width
conv0_table = ${table0_color${color}} # convolution table (optional)
conv0_table_in = 1 # conv input max, used if table file not defined
conv0_table_out = ${table0_max} # features max, used if table file not defined
conv0_weights = ${wroot0}${sp0}_layer1_convolution_kernel.mat
addc0_weights = ${wroot0}${sp0}_layer2_bias_bias.mat
diag0_weights = ${wroot0}${sp0}_layer4_diag_coeff.mat
wstd0_kerh = 7 # normalization kernel's height
wstd0_kerw = 7 # normalization kernel's width
subs1_kerh = 2 # subsampling kernel's height
subs1_kerw = 2 # subsampling kernel's width
subs1_strideh = ${subs1_kerh} # subsampling stride in height
subs1_stridew = ${subs1_kerw} # subsampling stride in width
addc1_weights = # weights to be loaded if manual_load = 1
conv2_kerh = 7 # convolution kernel's height
conv2_kerw = 7 # convolution kernel's width
conv2_strideh = 1 # convolution stride in height
conv2_stridew = 1 # convolution stride in width
conv2_table = ${table1} # convolution table (optional)
conv2_table_in = thickness # use current thickness as max table input
conv2_table_out = ${table1_max} # features max, used if table file not defined
conv2_weights = #${wroot1}${sp0}${sp1}_layer1_convolution_kernel.mat
addc2_weights = #${wroot1}${sp0}${sp1}_layer2_bias_bias.mat
diag2_weights = #${wroot1}${sp0}${sp1}_layer4_diag_coeff.mat
wstd2_kerh = 7 # normalization kernel's height
wstd2_kerw = 7 # normalization kernel's width
subs3_kerh = 2 # subsampling kernel's height
subs3_kerw = 2 # subsampling kernel's width
subs3_strideh = ${subs3_kerh} # subsampling stride in height
subs3_stridew = ${subs3_kerw} # subsampling stride in width
addc3_weights = # weights to be loaded if manual_load = 1
conv4_kerh = 15 # convolution kernel's height
conv4_kerw = 5 # convolution kernel's width
conv4_strideh = 1 # convolution stride in height
conv4_stridew = 1 # convolution stride in width
conv4_table_in = thickness # use current thickness as max table input
conv4_table_out = noutputs # use number of classes as max table output
linear5_in = 10 # linear module input features size
linear5_out = noutputs # use number of classes as max table output

# manual loading ##############################################################
sp0 = 03 #0703 2007 # 0301 1205 #03 07 12 # sparsity layer0
sp1 = #03 07 12 # sparsity layer1
wroot0 = /home/pierre/eblpierre/tools/demos/pedestrians/inria/koray/pedmachines/machine5732
#wroot0 = ${HOME}/koray/color/machine57
#wroot0 = /data/koray/pedmachines/machine5732
wroot1 = /data/koray/pedmachines2/machine95732

# tables #######################################################################

tblroot = ${ebl}/tools/data/tables/ # location of table files

# conv0
table0_max = 32 #64 # full table output max (overridden if table file defined)
table0_color0 = # no color, use table0_max for full table
table0_color1 = ${tblroot}/table_3_32_connect_32_fanin_0_density_0.33_yuv0_y26_u29_v32.mat

# conv1
tbl=1
table1_max = 64 # 64 96 128 256
tbl1_1 = ${tblroot}/table_32_64_connect_1664_fanin_26_density_0.81_random.mat
tbl1_2 = ${tblroot}/table_32_96_connect_2496_fanin_26_density_0.81_random.mat
table1 = ${tbl1_${tbl}}

# preprocessing ################################################################
resize = mean # bilinear
normalization_size = 7 # 9

# training #####################################################################
ds = 1 # dataset id
dsname = ${name}_${resize}${inputh}x${inputw}_ker${normalization_size}_bg
train = ${dsname}_train_${ds} # training set
val = ${dsname}_val_${ds} # validation set
#eta = .000005 .00002 # learning rate
eta = #.0000005 .000005 .00001 # learning rate
iterations = 20 # number of training iterations
ndiaghessian = 400 #800 1200 # number of sample for 2nd derivatives estimation
epoch_mode = 0 # 0: fixed number 1: show all at least once
epoch_size = 4000 # number of training samples per epoch. comment to ignore.
epoch_show_modulo = 100 # print message every n training samples
train_display = 0 # display training
sample_probabilities = 0 # use probabilities to pick samples
hardest_focus = 0 # 0: focus on easiest samples 1: focus on hardest ones
ignore_correct = 1 # If 1, do not train on correctly classified samples
min_sample_weight = 0 #.1 .5 1 # minimum probability of each sample
per_class_norm = 1 # normalize probabiliy by class (1) or globally (0)
shuffle_passes = 1 # shuffle samples between passes
balanced_training = 1 # show each class the same amount of samples or not
no_training_test = 1 # do not test on training set if 1
target_factor = 1 # multiply targets -1 and 1 by:
save_pickings = 1 # save sample picking statistics
binary_target = 0 # use only 1 output, -1 for negative examples, +1 for positive

# retraining ###################################################################
retrain = 0
retrain_weights = # ${root1}/${job_name_retraining}_net040.mat

# detection ####################################################################
nthreads = 1 # number of detection threads
ipp_cores = 1 # number of cores used by IPP
weights = ${root2}/${weights_file}
classes = ${root2}/${job_name}_classes.mat
threshold = .1 # confidence detection threshold
gain = 1
input_height = -1 # use -1 to use original size
input_width = -1 # use -1 to use original size
input_min = 0 # minimum height or width for minimum scale
input_max = 1200 # maximum height or width for maximum scale
scaling = 1.1 # scaling ratio between scales
min_scale = .75 # min scale as factor of minimal network size
max_scale = 1 # max scale as factor of original resolution
input_random = 1 # randomize input list (only works for 'directory' camera).
input_npasses = 1 # passes on the input list (only works for 'directory' cam).
hzpad = .3 # vertical zero padding on each side as ratio of network's min input
wzpad = .3 # horizontal zero padding on each side as ratio of network's min in
#mem_optimization = 1
bbox_saving = 1 # 0: none 1: all styles 2: eblearn style 3: caltech style
max_object_hratio = 0 #13.5 # image's height / object's height, 0 to ignore

# nms (non-maximum suppression) ################################################
nms = 1 # 0: no pruning 1: ignore overlapping bb 2: pedestrian custom
bbox_file = ${HOME}/ped/bbox101_${set}_raw.txt # ignore processing, feed pre-computed bboxes to nms
bbhfactor = .6 .65 #.745 # height factor to apply to bounding boxes
bbwfactor = .4 .45 # .6575 # width factor to apply to bounding boxes
bbhfactor2 = 1.1 1.0534 #1.145 #.745 # .65
bbwfactor2 = 1.5 1.43 #1.46 # .6575 # .45
confidence_type = 2 # 0: sqrdist 1: single output 2: max other (recommended)
max_bb_overlap = .3 # minimum ratio with smallest bbox to declare overlap
min_hcenter_dist = .3 .4 # centers closer than this ratio over height cancel out
min_wcenter_dist = .4 # centers closer than this ratio over width cancel out

# evaluation ###################################################################
set = train
evaluate = 1
evaluate_cmd = "${visiongrader} ${visiongrader_params}"
visiongrader = ${HOME}/visiongrader/main.py
visiongrader_params = "${input_params} ${groundtruth_params} ${compare_params} ${curve_params}"
input_params = "--input bbox.txt --input_parser eblearn --sampling 50 "
annotations_test = ${root}/../INRIAPerson/Test/annotations/
annotations_train = ${root}/../INRIAPerson/Train/annotations/
groundtruth_params = "--groundtruth ${annotations_${set}} --groundtruth_parser inria --gt_whratio .43 "
compare_params = "--comparator overlap50percent --comparator_param .5 "
curve_params = "--det --saving-file curve.pickle --show-no-curve "
input_dir = ${input_dir_${set}}
input_dir_test = /home/sermanet/${machine}data/ped/inria/INRIAPerson/Test/pos
input_dir_train = /home/sermanet/${machine}data/ped/inria/INRIAPerson/Train/pos

# detection display ############################################################
skip_frames = 0 # skip this number of frames before each processed frame
save_detections = 0 # output saving and display
save_max = 25000 # Exit when this number of objects have been saved
save_max_per_frame = 10 # Only save the first n objects per frame
save_video = 0 # save each classified frame and make a video out of it
save_video_fps = 5
use_original_fps =0
display = 1
display_threads = 0 # each thread displays on its own
display_states = 0 # display internal states of 1 resolution
show_parts = 0 # show parts composing an object or not
silent = 0 # minimize outputs to be printed
sync_outputs = 1 # synchronize output between threads
minimal_display = 0 # only show classified input
display_sleep = 0 # sleep in milliseconds after displaying
ninternals = 1
# demo display variables
queue1 = 0
qstep1 = 1
qheight1 = 5
qwidth1 = 2
queue2 = 0
qstep2 = 50
qheight2 = 5
qwidth2 = 5
precamera = 0 # pre-camera (used before regular camera)
precamdir = ${root2}/

camera = directory # camera options: opencv shmem video directory
# limit of input video duration in seconds, 0 means no limit
input_video_max_duration = 0 
# step between input frames in seconds, 0 means no step
input_video_sstep = 0

# training-generated variables #################################################
job_name=20101024.222755.inria_irisa_09_retraining_conf01_eta_.000005
classes = ${root2}/${job_name}_classes.mat
weights_file = 20101024.222755.inria_irisa_12_retraining_conf01_eta_.000005_net015.mat
root2 = ${HOME}/20101024.222755.inria_irisa/
