################################################################################
# metarun configuration
# Note: variables starting with "meta_" are reserved for meta configuration

meta_command = train # command to run
# optional meta variables ######################################################
meta_name = ${name}_${machine} # name of this meta job
meta_max_cpus = 8 # maximum number of cpus to use at the same time
meta_output_dir = ${root}/../out/ # directory where to write outputs
meta_gnuplot_params="set grid ytics;set ytics;set mytics;set grid mytics;set logscale y; set mxtics; set grid xtics; " # extra gnuplot parameters
# analyze processes output or not. if 0, the meta_trainer will have no notion
# of iteration and will only send 1 report at the very end.
# if 1, meta_trainer will try to find iteration and other variable values
# in each process' output.
meta_analyze = 1
meta_send_email = 1 # emailing results or not
meta_email=${myemail} # email to use (use environment variable "myemail")
# iterations at which to send an email
meta_email_iters = 0,1,2,3,4,5,7,10,15,20,30,50,75,100,200
meta_email_period = 1 # send email with this freq (if email_iters not defined)
meta_watch_interval = 30 # interval sec to analyze outputs and check who's alive
# variables to minimize, process and iteration with lowest value will
# be used to report best weights, or start consequent training
meta_minimize = test_errors,errors,test_energy,energy
meta_sticky_vars = job,config,classes # vars to keep around at each iterations
meta_send_best = 5 # send n best answers that minimize meta_minimize's value

################################################################################
# local program configuration

name=inria
machine = ${HOSTNAME}a
ebl= ${HOME}/eblearn/ # eblearn root
root = ${HOME}/${machine}data/ped/${name}/ds/ # datasets root
#root2 = ${ebl}/demos/pedestrians/trained/ # trained weights root

# network ######################################################################
net_type = cscsc
net_ih = 80
net_iw = 40
net_c1h = 9
net_c1w = 9
net_s1h = 2
net_s1w = 2
net_c2h = 7
net_c2w = 7
net_s2h = 3
net_s2w = 2
# net_full = 100
absnorm = 1
color = 0
mirror = 0
use_tanh = 1
use_shrink = 0

# if defined, those variable force to use full connections with those maximums
#table0_max = 32 #64
table1_max = 64 # 96 # 128 256

tblroot = ${ebl}/data/tables/
tbl1_1 = ${tblroot}/table_32_64_connect_1664_fanin_26_density_0.81_random.mat
tbl1_2 = ${tblroot}/table_32_96_connect_2496_fanin_26_density_0.81_random.mat

tbl=1
#table0 = ${tblroot}/${${tbl}_0}
#table1 = ${tbl1_${tbl}}
#table2 = ${tblroot}/${${tbl}_2}
 
koray = 1
koray_dir = /home/sermanet/koray/

#wkoray = enc736401.obj enc736425.obj
#wkoray = enc736407.obj
#wkoray = enc736420.obj enc736403.obj
wkoray = enc736412.obj # enc736409.obj # enc736415.obj
#wkoray = enc736430.obj enc736405.obj

table0 = ${koray_dir}/table0.mat #${wkoray}_conv0_table.mat
#table1 = ${koray_dir}/table1.mat
#table2 = ${koray_dir}/table2.mat

# preprocessing ################################################################
resize = mean # bilinear
normalization_size = 7 # 9

# training #####################################################################
ds = 1 # dataset id
dsname = ${name}_${resize}${net_ih}x${net_iw}_ker${normalization_size}_bg
train = ${dsname}_train_${ds} # training set
val = ${dsname}_val_${ds} # validation set
eta = .00002 # learning rate
iterations = 5 # number of training iterations
ndiaghessian = 400 # number of sample for 2nd derivatives estimation
epoch_mode = 1 # 0: fixed number 1: show all at least once
epoch_show_modulo = 100 # print message every n training samples
#epoch_size = 100 # number of training samples per epoch. comment to ignore.
train_display = 0 # display training
sample_probabilities = 1 # use probabilities to pick samples (easiest less probable)
min_sample_weight = 0 .1 .5 1 # minimum probability of each sample
per_class_norm = 1 # normalize probabiliy by class (1) or globally (0)
shuffle_passes = 1 # shuffle samples between passes
balanced_training = 1 # show each class the same amount of samples or not
no_training_test = 1 # do not test on training set if 1
target_factor = 1 # multiply targets -1 and 1 by:
save_pickings = 1 # save sample picking statistics

# retraining ###################################################################
retrain = 0
retrain_weights = # ${root1}/${job_name_retraining}_net040.mat

# detection ####################################################################
weights = ${root2}/${weights_file}
classes = ${root2}/${job_name}_classes.mat
threshold = .99 # confidence detection threshold
gain = 1
input_height = -1 # use -1 to use original size
input_width = -1 # use -1 to use original size
input_max = 800
scaling = 1.3 # scaling ratio between scales
max_scale = 1 # max scale as factor of original resolution
input_random = 1 # randomize input list (only works for 'directory' camera).
input_npasses = 1 # passes on the input list (only works for 'directory' cam).
bbhfactor = .85 # height factor to apply to bounding boxes
bbwfactor = .55 # width factor to apply to bounding boxes
pruning = 1 # prune overlapping bounding boxes or not
bbh_overlap = .9 # minimum height ratio with smallest bbox to declare overlap
bbw_overlap = 0 # minimum width ratio with smallest bbox to declare overlap
foot_overlap = .3 # maximum overlap authorized when footline is same
nthreads = 8 # number of detection threads
ipp_cores = 1 # number of cores used by IPP
hzpad = 0 # vertical zero padding on each side
wzpad = 0 # horizontal zero padding on each side
#mem_optimization = 1

# detection display ############################################################
save_detections = 1 # output saving and display
save_max = 25000 # Exit when this number of objects have been saved
save_max_per_frame = 10 # Only save the first n objects per frame
save_video = 0 # save each classified frame and make a video out of it
save_video_fps = 5
use_original_fps =0
display = 1
minimal_display = 1 # only show classified input
display_sleep = 0 # sleep in milliseconds after displaying
ninternals = 1
# demo display variables
queue1 = 0
qstep1 = 1
qheight1 = 5
qwidth1 = 2
queue2 = 0
qstep2 = 50
qheight2 = 5
qwidth2 = 5
precamera = 0 # pre-camera (used before regular camera)
precamdir = ${root2}/

camera = directory # camera options: opencv shmem video directory
# limit of input video duration in seconds, 0 means no limit
input_video_max_duration = 0 
# step between input frames in seconds, 0 means no step
input_video_sstep = 0

# training-generated variables ####################################################
