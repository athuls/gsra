################################################################################
# META_TRAINER CONFIGURATION
# Note: variables starting with "meta_" are reserved for meta configuration

# required variables
meta_command = train

# optional meta variables ######################################################

# name of this meta job
meta_name = ped_${machine}
# maximum number of cpus to use at the same time
meta_max_cpus = 8
# directory where to write outputs of all processes
meta_output_dir = ${root}/../out/
# extra gnuplot parameters
meta_gnuplot_params="set grid ytics;set ytics;set mytics;set grid mytics;set logscale y; set mxtics; set grid xtics; "

# analyze processes output or not. if 0, the meta_trainer will have no notion
# of iteration and will only send 1 report at the very end.
# if 1, meta_trainer will try to find iteration and other variable values
# in each process' output.
meta_analyze = 1

# emailing results or not
meta_send_email = 1
# email to use (use environment variable "myemail")
meta_email=${myemail}
# iterations at which to send an email
meta_email_iters = 0,1,2,3,4,5,7,10,15,20,30,50,75,100,200
# send email with this frequency (if email_iters not defined)
meta_email_period = 1

# interval in seconds to analyze processes output, and to check who is alive.
meta_watch_interval = 30
# variables to minimize, process and iteration with lowest value will
# be used to report best weights, or start consequent training
meta_minimize = test_errors,errors,test_energy,energy
# variables to keep around at each iterations
meta_sticky_vars = job,config,classes
# send n best answers that minimize meta_minimize's value
meta_send_best = 5

################################################################################
# LOCAL PROGRAM CONFIGURATION

machine = ${HOSTNAME}a
dset = _nicta

# directories ##################################################################
root = /home/sermanet/${machine}data/pedestrians/ds3
#root2 = /home/sermanet/eblearn/demos/objrec/ped/trained/
#root2 = /data/ped

# network ######################################################################
net_type = cscsc
net_ih = 80 # 48 # 64
net_iw = 32
net_c1h = 5
net_c1w = 5
net_s1h = 2
net_s1w = 2
net_c2h = 6
net_c2w = 5
net_s2h = 3
net_s2w = 2
net_full = 100
absnorm = 0 1
color = 0 # 1
mirror = 0
use_tanh = 0
use_shrink = 0 1

# training #####################################################################
ds = 1
dsname = ped${dset}_${resize}${net_ih}x${net_iw}_ker${normalization_size}_bg${fp_name}
train = ${dsname}_train_${ds}
val = ${dsname}_val_${ds}
eta = .00001 .000001
iterations = 2
# number of training samples per epoch. comment to ignore.
#epoch_size = 100
train_display = 0
# use probabilities to pick samples (easiest less probable)
wsamples = 1
# minimum probability of each sample
min_sample_weight = 1
# normalize probabiliy by class (1) or globally (0)
wnorm = 0
# shuffle samples between passes
shuffle_passes = 1
# show each class the same amount of samples or not
balanced_training = 1

# retraining ###################################################################
retrain = 0
job_name_retraining = 
fp_name = #_${job_name_retraining}
retrain_weights = # ${root1}/${job_name_retraining}_net040.mat
retrain_dir = 

# preprocessing ################################################################
resize = mean # bilinear
normalization_size = 7 # 9

# detection ####################################################################
weights = ${root2}/${weights_file}
classes = ${root2}/${job_name}_classes.mat
threshold = .99
gain = 1
input_height = -1 # use -1 to use original size
input_width = -1 # use -1 to use original size
input_max = 400
scaling = 1.4

# output saving and display
save_detections = 1
# Exit when this number of objects have been saved
save_max = 25000
# Only save the first n objects per frame
save_max_per_frame = 10
# save each classified frame and make a video out of it
save_video = 0
save_video_fps = 5
use_original_fps =0
display = 1
# only show classified input
minimal_display = 1
# sleep in milliseconds after displaying
display_sleep = 0
ninternals = 1
# demo display variables
queue1 = 0
qstep1 = 1
qheight1 = 5
qwidth1 = 2
queue2 = 0
qstep2 = 50
qheight2 = 5
qwidth2 = 5
# pre-camera variables (used before regular camera)
precamera = 0
precamdir = ${root2}/

# camera options: opencv shmem video directory
camera = directory

# limit of input video duration in seconds, 0 means no limit
input_video_max_duration = 0

# step between input frames in seconds, 0 means no step
input_video_sstep = 0

# koray unsupervised experiement ###############################################
net_type = cscsc
net_ih = 80 # 48 # 64
net_iw = 32
net_c1h = 9
net_c1w = 9
net_s1h = 2
net_s1w = 2
net_c2h = 7
net_c2w = 5
net_s2h = 3
net_s2w = 2
absnorm = 0 1
color = 0
mirror = 0
use_tanh = 0
use_shrink = 0 1

# do not test on training set
no_training_test = 1
# multiply targets -1 and 1 by:
target_factor = 1.5

koray = 1
koray_dir = /home/sermanet/koray/

#wkoray = enc736401.obj enc736425.obj 
#wkoray = enc736407.obj 
#wkoray = enc736420.obj enc736403.obj 
wkoray = enc736412.obj # enc736409.obj # enc736415.obj 
#wkoray = enc736430.obj enc736405.obj

table0 = ${koray_dir}/table0.mat #${wkoray}_conv0_table.mat
table1 = ${koray_dir}/table1.mat
table2 = ${koray_dir}/table2.mat
