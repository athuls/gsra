################################################################################
# META_TRAINER CONFIGURATION
# Note: variables starting with "meta_" are reserved for meta configuration

# required variables
meta_command = run.sh

# optional variables
meta_name = 001_def2
meta_max_cpus = 8
meta_output_dir = output2
meta_email = pierre.sermanet@gmail.com
meta_email_period = 1 # send a email with plots after every n iterations
meta_gnuplot_params = set grid ytics;set ytics 5;set mytics 5;set grid mytics; set yrange [0:100];

################################################################################
# LOCAL PROGRAM CONFIGURATION

;;eblearn-path = /home/pierre/eblush/eblearn/code
eblearn-path = /home/sermanet/eblush/eblearn/code

;; 0 = training all
;; 1 = training top layer only
;; 2 = testing
mode = 1

;; actual LUSH CODE to load
;;lush-code = run-classifier-drlim.lsh
;;lush-code = run-classifier-pp.lsh
lush-code = run-classifier-linear.lsh
;;lush-code = compute-features.lsh
;;lush-code = compute-drlim.lsh

;; parameters for saving the OUTPUTS from this run
output-folder = outputs.c101.final2

;; MAX nuber of ITERATIONS to do
maxiter = 100
drlimiter = 20

;; size of kernels
nrpixr = 9
nrpixc = 9

;; subsampling kernels
;; 1st layer
dski1 = 10
dskj1 = 10
dssi1 = 5
dssj1 = 5
;; 2nd layer
dski2 = 6
dskj2 = 6
dssi2 = 4
dssj2 = 4

;; size for classifier layer kernels
nrpixr_cl = 4
nrpixc_cl = 4
maxrandtable = 64

l1-deriv-thres = 1e-6

;; if you want to compute the HESSIAN
compute-hessian = 1
update-hessian = 1 ;; update hessian every this number of epochs

;; LEARNING RATES 
eta = .000005 .00005 .0005
anneal-value = 0.0125 ;; ~1/15 ~ half after 15 iterations
anneal-interval = 1

etasim = .001 .0001 ;; the learning rate for similar pairs
etadis = .00001 .0001 ;; the learning rate for dissimilar pairs

;; the parameters associated with the loss function.
;; --  for sq-sq= loss-args = margin
;; margin should be 1/4 of the maximum euclidean distance in the output space=
;; with 256 outputs, which range is -1.7 .. 1.7 (negative and positive saturaiton of
;; the sigmoid), the max euclidean is 3.4^2 * 256 = 11.56 * 256 = 2959.36
;; so 1/4 * 2959 = 739
;; or 1/10 * 2959 = 295
;; or 1/20 * 2959 = 148
loss-args = 148

;; regularization terms
ridge-wd = 0.0001      ;; L2
lasso-wd = 0.0001      ;; L1

;; data source parameters - the std. is 25.5 on zero-mean patches
bias = 0
coeff = 1

conn-table = rand-table.mat
weight-matf = weighted_window9_lush.mat

exper-nr = 1025
paramfile1 = coderparam1.mat
paramfile2 = coderparam11.mat
paramfile3 = siamparam.mat
randtablec3-fname = randtable-c3.mat
;;paramfile3 = exper2242/param2242-20.mat
;;paramfile-full = param81242-9.mat

;; regular
dfile =         /scratch/sermanet/datasets/c101_1_Yp_train_images.mat_features_drlim
dfile-lbl =     /scratch/sermanet/datasets/c101_1_Yp_train_labels.mat
dfile-pairs =   /scratch/sermanet/datasets/c101_1_Yp_train_defpairs.mat
dfile-ts =      /scratch/sermanet/datasets/c101_1_Yp_test_images.mat_features_drlim
dfile-ts-lbl =  /scratch/sermanet/datasets/c101_1_Yp_test_labels.mat

;; color
;dfile = /scratch/sermanet/datasets/c101_1_VpH2SV_train_images.mat
;dfile-lbl = /scratch/sermanet/datasets/c101_1_VpH2SV_train_labels.mat
;dfile-ts = /scratch/sermanet/datasets/c101_1_VpH2SV_test_images.mat
;dfile-ts-lbl =  /scratch/sermanet/datasets/c101_1_VpH2SV_test_labels.mat

;; deformations
;dfile =         /scratch/sermanet/datasets/c101_1_def5t5_Yp_train_images.mat_features_drlim
;dfile-lbl =     /scratch/sermanet/datasets/c101_1_def5t5_Yp_train_labels.mat
;dfile-pairs =   /scratch/sermanet/datasets/c101_1_def5t5_Yp_train_defpairs.mat
;dfile-ts =      /scratch/sermanet/datasets/c101_1_def5t5_Yp_test_images.mat_features_drlim
;dfile-ts-lbl =  /scratch/sermanet/datasets/c101_1_def5t5_Yp_test_labels.mat

;;ntrdata = 200
;;ntedata = 200
