################################################################################
# META_TRAINER CONFIGURATION
# Note: variables starting with "meta_" are reserved for meta configuration

# required variables
meta_command = objrec_train

# optional variables
meta_name = face
meta_max_cpus = 8
#meta_output_dir = /home/sermanet/texieradata/face/out
meta_output_dir = /home/sermanet/humairadata/face/out
meta_email = me@mail.com
meta_email_period = 1 # send an email with plots after every n iterations
meta_gnuplot_params ="set grid ytics;set ytics 5;set mytics 5;set grid mytics;"

################################################################################
# LOCAL PROGRAM CONFIGURATION

# directories ##################################################################
root=/home/sermanet/humairadata/face/ds
root2=${HOME}/eblearn/demos/face/trained/
#root2=C:\Users\pierre\eblearn\demos\obj\face\trained\

# network ######################################################################
net_type=cscsc
net_ih=32
net_iw=32
net_c1h=5
net_c1w=5
net_s1h=2
net_s1w=2
net_c2h=5
net_c2w=5
net_s2h=2
net_s2w=2
net_full=100
absnorm=1
color=0
mirror=0
use_tanh = 1

# training #####################################################################
ds=1
val_size=500
dsname=all_mean32x32_ker7_bg_20100223.002945.face_conf00_eta_.00001
train=all_mean32x32_ker7_bg_20100223.002945.face_conf00_eta_.00001_train_500_1
val=all_mean32x32_ker7_bg_20100223.002945.face_conf00_eta_.00001_val_500_1
eta=.000005
iterations=150

# retraining ###################################################################
retrain=1
job_name_retraining=20100223.002945.face_conf00_eta_.00001
fp_name=_20100223.002945.face_conf00_eta_.00001
retrain_weights=/home/sermanet/eblearn/demos/objrec/face/trained//20100223.002945.face_conf00_eta_.00001_net029.mat

# preprocessing ################################################################
resize=mean
normalization_size=7

# tracking ####################################################################
mainsleep = 5
smooth_factor = 1.0
# display tracking
tracking_display = 0

# detection ####################################################################
weights=${root2}/20100227.175046.face_conf05_eta_.000005_retrain_1_net044.mat
classes=${root2}/20100227.175046.face_conf05_eta_.000005_retrain_1_classes.mat
threshold=-.1
gain=1
input_height=-1#120#480
input_width=-1#160#640
#input_min=100
input_max=800
# scaling ratio between scales
scaling = 1.3
# scale factor of maximum resolution of the original resolution
max_scale = 1.0
# scale factor of minimum resolution of the original resolution
min_scale = 1.0
# number of detection threads
nthreads = 1
# randomize image input list (only works for 'directory' camera).
input_random = 0
# number of passes on the image input list (only works for 'directory' camera).
input_npasses = 1
# height factor to apply to bounding boxes
bbhfactor = 1
# width factor to apply to bounding boxes
bbwfactor = 1
# prune overlapping bounding boxes or not
pruning = 1
# minimum height ratio with smallest bbox to declare overlap
bbh_overlap = .67
# minimum width ratio with smallest bbox to declare overlap
bbw_overlap = 0
hzpad = .5 # vertical zero padding on each side
wzpad = .5 # horizontal zero padding on each side
mem_optimization = 1

# detection display ############################################################
# output saving and display
save_detections=0
# save each classified frame and make a video out of it
save_video=0
# fps at which video should be constructed
save_video_fps=1
# if loaded a video and equal to 1, reuse video's fps
use_original_fps=0
# enable or disable display
display = 1
# only show classified input
minimal_display = 0
# display internal states of network
display_states = 0
# sleep in milliseconds after displaying
display_sleep = 0
ninternals=1
# demo display variables
queue1 = 0
qstep1 = 1
qheight1 = 5
qwidth1 = 2
queue2 = 0
qstep2 = 50
qheight2 = 5
qwidth2 = 5
# pre-camera variables (used before regular camera)
precamera = 0
precamdir = ${root2}/

# camera options: v4l2 opencv shmem video directory
camera = directory # v4l2 #opencv # directory
device = /dev/video0

# limit of input video duration in seconds, 0 means no limit
input_video_max_duration=0

# step between input frames in seconds, 0 means no step
input_video_sstep=1500

job_name=20100227.175046.face_conf05_eta_.000005_retrain_1 # variable added by meta_trainer
